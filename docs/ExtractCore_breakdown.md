# Detailed Breakdown of Core Microbiome Functions
### Generated by ChatGPT03.mini.high
Prompted by Bolívar Aponte Rolón

This document provides an in‐depth explanation of two key functions from the `000_core_microbiome_functions.R` file. These functions are used to extract a “core” microbial community from a phyloseq object based on abundance-occupancy distributions and to fit a neutral model to an OTU table. The functions were developed and adapted from Shade and Stopnisek (2019), VanWallendael et al. (2021), and further updated by various collaborators.

---

## Overview of the File

Before the functions, several packages are loaded, including `phyloseq`, `vegan`, `tidyverse`, and others. These packages provide the tools for microbial community analysis, statistical modeling, data wrangling, and visualization.

---

## Function 1: `ExtractCore`

### Purpose

The `ExtractCore` function extracts core microbial taxa from a phyloseq object. Core taxa are determined based on:
- Their occupancy (the proportion of samples in which they appear)
- Their mean relative abundance
- Their contribution to overall Bray-Curtis dissimilarity

A threshold (default ~2% of variation, manipulated via the function’s logic) is used to define what constitutes a “core” taxon.

### Function Signature

```r
ExtractCore <- function(physeq, Var, method, Group=NULL, Level=NULL)
```


**physeq**: A phyloseq object containing your community data.
**Var**: A variable (typically a factor) used to group samples for calculating detection frequency.
**method**: A character string specifying how to choose the core threshold (e.g., "elbow" or another method based on increase in Bray-Curtis similarity).
**Group** (optional): A grouping variable to subset the phyloseq object.
**Level** (optional): The levels within the grouping variable to include.
### Step-by-Step Breakdown

#### 1. Setting the Random Seed

```r
set.seed(37920)
```

- **Purpose:**  
    Sets the seed for random number generation to ensure reproducibility (important for rarefaction and any stochastic processes).

#### 2. Rarefaction and Taxonomy Table Extraction

```r
if (min(sample_sums(physeq)) == max(sample_sums(physeq))) {
  nReads = min(sample_sums(physeq))
  rare <- physeq
  taxon <- as(tax_table(rare), "matrix")
  taxon <- as.data.frame(taxon)
  dim(taxon)  %T>% print()
} else {
  nReads = min(sample_sums(physeq))
  rare <- rarefy_even_depth(physeq, sample.size = nReads,
                             trimOTUs = TRUE, replace = TRUE,
                             verbose = FALSE)
  taxon <- as(tax_table(rare), "matrix")
  taxon <- as.data.frame(taxon)
}

```

- **Explanation:**
    - Checks if all samples have the same sequencing depth.
    - If they do, no rarefaction is needed; the minimum sample sum (`nReads`) is used.
    - Otherwise, the function performs even-depth rarefaction (subsampling wiht replacement is forced by `trimOTUs = TRUE` and `replace = TRUE`).
    - The taxonomy table is converted from a phyloseq tax_table to a matrix and then a data frame.
    - The dimensions of the taxonomy table are printed for verification.

#### 3. Handling Optional Grouping

```r
if (is.null(Group)) {
  otu <- rare@otu_table %>% as("matrix")
  map <- rare@sam_data %>% as("data.frame")
} else{
  sub_group <- substitute(Group)
  sub_set <- subset(sample_data(rare), eval(parse(text=sub_group)) %in% Level)
  physeq1 <- merge_phyloseq(otu_table(rare),
                            tax_table(rare),
                            refseq(rare),
                            sub_set)
  otu_table(physeq1) <- otu_table(physeq1)[which(rowSums(otu_table(physeq1)) > 0), ]
  otu <- physeq1@otu_table %>% as("matrix")
  map <- physeq1@sam_data %>% as("data.frame")
  print("Grouping Factor")
  map[,Group] %T>% print()
  taxon <- as(tax_table(physeq1), "matrix")
  taxon <- as.data.frame(taxon)
}
map$SampleID <- rownames(map)

```

- **Explanation:**
    - If no grouping factor is specified, the OTU table and sample metadata are extracted directly.
    - If a grouping factor is provided, the sample data is subset based on `Group` and `Level`, and the phyloseq object is reconstructed using only these samples.
    - Any OTU with a zero total count is removed.
    - The sample metadata is augmented with a `SampleID` column.

#### 4. Calculating Occupancy and Mean Relative Abundance

```r
otu_PA <- 1 * ((otu > 0) == 1)  # Convert counts to binary presence/absence
otu_occ <- rowSums(otu_PA) / ncol(otu_PA)  # Proportion of samples where each OTU is present
otu_rel <- apply(decostand(otu, method = "total", MARGIN = 2), 1, mean)  # Average relative abundance
occ_abun <- add_rownames(as.data.frame(cbind(otu_occ, otu_rel)), "otu")

```

- **Explanation:**
    - `otu_PA` creates a binary matrix indicating presence (1) or absence (0) of each OTU.
    - `otu_occ` calculates the occupancy (proportion of samples with the OTU).
    - `otu_rel` calculates the mean relative abundance by standardizing each sample (using `decostand`) and taking the mean across samples.
    - The two metrics are combined into a data frame (`occ_abun`), with OTU identifiers as a new column.

#### 5. Ranking OTUs Based on Occurrence

```r
Var <- enquo(Var)  # Convert Var for tidy evaluation
PresenceSum <-
  data.frame(otu = as.factor(row.names(otu)), otu) %>%
  gather(SampleID, abun,-otu) %>%
  left_join(map, by = "SampleID") %>%
  group_by(otu, !!Var) %>%
  dplyr::summarise(
    time_freq = sum(abun > 0) / length(abun), 
    coreTime = ifelse(time_freq == 1, 1, 0)
  ) %>%
  group_by(otu) %>%
  dplyr::summarise(
    sumF = sum(time_freq),
    sumG = sum(coreTime),
    nS = length(!!Var)* 2,
    Index = (sumF + sumG) / nS
  )

```
- **Explanation:**
    - Converts the OTU table to a long format where each row represents an OTU's abundance in a sample.
    - Joins this data with the sample metadata.
    - Groups by OTU and the variable `Var` to calculate:
        - `time_freq`: the frequency of detection for each OTU in each group.
        - `coreTime`: a binary indicator that is 1 if an OTU is present in every sample within a group.
    - Summarizes these measures across groups to compute an overall ranking index (`Index`) for each OTU.

#### 6. Merging and Sorting OTU Rankings

```r
otu_ranked <- occ_abun %>%
  left_join(PresenceSum, by = "otu") %>%
  transmute(otu = otu, rank = Index) %>%
  arrange(desc(rank))

```

- **Explanation:**
    - Joins the occupancy/abundance data with the presence summary to create a ranking.
    - Orders OTUs by the calculated ranking index in descending order (highest ranking first).

#### 7. Calculating Bray-Curtis Dissimilarity (BC) for the Top OTU

```r
otu_start = otu_ranked$otu[1]
start_matrix <- as.matrix(otu[otu_start, ])
start_matrix <- t(start_matrix)
x <- apply(combn(ncol(start_matrix), 2), 2, function(x)
  sum(abs(start_matrix[, x[1]] - start_matrix[, x[2]])) / (2 * nReads))
x_names <- apply(combn(ncol(start_matrix), 2), 2, function(x)
  paste(colnames(start_matrix)[x], collapse = "-"))
df_s <- data.frame(x_names,x)
names(df_s)[2] <- 1 

```

- **Explanation:**
    - Selects the top-ranked OTU and extracts its abundance across samples.
    - Transposes the vector into a matrix.
    - Calculates pairwise Bray-Curtis dissimilarities among samples using the formula: $\text{BC} = \frac{\sum \text{abs}(x_i - x_j)}{2 \times \text{nReads}}$
    - Stores these values along with sample pair names in a data frame.

#### 8. Iteratively Adding OTUs to Compute Cumulative BC Dissimilarity

```r
BCaddition <- NULL
BCaddition <- rbind(BCaddition, df_s)
for(i in 2:411){ 
  otu_add = otu_ranked$otu[i]
  add_matrix <- as.matrix(otu[otu_add,])
  add_matrix <- t(add_matrix)
  start_matrix <- rbind(start_matrix, add_matrix)
  y <- apply(combn(ncol(start_matrix), 2), 2, function(y)
    sum(abs(start_matrix[, y[1]] - start_matrix[, y[2]])) / (2 * nReads))
  df_a <- data.frame(x_names, y)
  names(df_a)[2] <- i 
  BCaddition <- left_join(BCaddition, df_a, by = c('x_names'))
}

```

- **Explanation:**
    - Initializes an empty data structure (`BCaddition`).
    - For each subsequent OTU (from the 2nd to the 411th ranked), it:
        - Extracts its abundance vector, transposes it, and appends it to the current matrix.
        - Recalculates the pairwise Bray-Curtis dissimilarities for the augmented matrix.
        - Joins the new dissimilarity values to the cumulative data frame.

#### 9. Computing the Full Bray-Curtis Dissimilarity for All OTUs

```r
z <- apply(combn(ncol(otu), 2), 2, function(z)
  sum(abs(otu[, z[1]] - otu[, z[2]])) / (2 * nReads))
x_names <- apply(combn(ncol(otu), 2), 2, function(x)
  paste(colnames(otu)[x], collapse = "-"))
df_full <- data.frame(x_names, z)
names(df_full)[2] <- length(rownames(otu))
BCfull <- left_join(BCaddition, df_full, by='x_names')

```

- **Explanation:**
    - Calculates pairwise Bray-Curtis dissimilarity for the entire OTU table.
    - Merges this complete dissimilarity matrix (`df_full`) with the cumulative matrix (`BCaddition`).

#### 10. Ranking the Cumulative Bray-Curtis Dissimilarity

```r
rownames(BCfull) <- BCfull$x_names
temp_BC <- BCfull
temp_BC$x_names <- NULL
temp_BC_matrix <- as.matrix(temp_BC)
BC_ranked <- data.frame(rank = as.factor(row.names(t(temp_BC_matrix))), t(temp_BC_matrix)) %>% 
  gather(comparison, BC, -rank) %>%
  group_by(rank) %>%
  summarise(MeanBC = mean(BC)) %>%            
  arrange(desc(-MeanBC)) %>%
  mutate(proportionBC = MeanBC / max(MeanBC))
Increase = BC_ranked$MeanBC[-1] / BC_ranked$MeanBC[-length(BC_ranked$MeanBC)]
increaseDF <- data.frame(IncreaseBC = c(0, Increase), rank = factor(c(1:(length(Increase)+1))))
BC_ranked <- left_join(BC_ranked, increaseDF)
BC_ranked <- BC_ranked[-nrow(BC_ranked),]
BC_ranked <- drop_na(BC_ranked)

```

- **Explanation:**
    - Converts the cumulative Bray-Curtis dissimilarity data to a matrix and transposes it.
    - Calculates the mean Bray-Curtis dissimilarity (MeanBC) for each rank.
    - Ranks the dissimilarities and computes the proportion of BC explained.
    - Computes the increase in BC between successive cumulative additions.
    - Depending on the method specified, this information is used to determine a threshold for core OTU selection.

#### 11. Core OTU Selection Based on Method

```r
if (method=="elbow"){
  fo_difference <- function(pos){
    left <- (BC_ranked[pos, 2] - BC_ranked[1, 2]) / pos
    right <- (BC_ranked[nrow(BC_ranked), 2] - BC_ranked[pos, 2]) / (nrow(BC_ranked) - pos)
    return(left - right)
  }
  BC_ranked$fo_diffs <- sapply(1:nrow(BC_ranked), fo_difference)
  elbow <- which.max(BC_ranked$fo_diffs)
  core_otus <- otu_ranked$otu[1:elbow]
} else{
  lastCall <- as.numeric(as.character(dplyr::last(
    subset(BC_ranked, IncreaseBC >= 1.02)$rank)))
  core_otus <- otu_ranked$otu[1:lastCall]
}

```

- **Explanation:**
    - **Elbow Method:**  
        A function (`fo_difference`) calculates the difference in slopes (left vs. right) of the BC curve at each point. The position with the maximum difference indicates the “elbow,” used to select core OTUs.
    - **Alternate Method:**  
        Uses a threshold (increase in BC similarity of ≥ 1.02) to determine the cutoff.
    - Core OTUs are then selected from the ranked OTU list up to the determined index.

#### 12. Flagging Core OTUs and Returning Results

```r
occ_abun$fill <- 'no'
occ_abun$fill[occ_abun$otu %in% core_otus] <- "core"
return_list <- list(core_otus, BC_ranked, otu_ranked, occ_abun, otu, map, taxon)
return(return_list)

```

- **Explanation:**
    - A new column `fill` is added to the occupancy-abundance data frame (`occ_abun`) to flag OTUs that are part of the core (set to `"core"`) versus non-core (set to `"no"`).
    - The function returns a list containing:
        1. The vector of core OTU identifiers.
        2. The Bray-Curtis ranking statistics.
        3. The ranked OTU data.
        4. The occupancy-abundance data with core flags.
        5. The OTU matrix.
        6. The sample metadata.
        7. The taxonomic data.

---

## Function 2: `sncm.fit`

### Purpose

The `sncm.fit` function fits a neutral community model to an OTU table, evaluating how well the observed frequency of OTUs matches predictions from a neutral model. It compares a neutral model fit with binomial and Poisson alternatives, providing model parameters, goodness-of-fit statistics, and confidence intervals.

### Function Signature

```r
sncm.fit <- function(spp, pool=NULL, stats=TRUE, taxon=NULL)

```

- **spp:** An OTU table (matrix or data frame) with counts.
- **pool (optional):** An alternative data pool for calculating mean abundances.
- **stats:** If `TRUE`, returns a summary of model fit statistics; if `FALSE`, returns detailed predictions.
- **taxon (optional):** A taxonomic table to merge with model predictions.

### Step-by-Step Breakdown

#### 1. Calculating Average Number of Individuals per Community

```r
N <- mean(apply(spp, 1, sum))
```

- **Explanation:**  
    Computes the average total count (number of individuals) per sample by summing counts across OTUs for each sample and then averaging these sums.

#### 2. Calculating Mean Relative Abundance

```r
if(is.null(pool)){
  p.m <- apply(spp, 2, mean)
  p.m <- p.m[p.m != 0]
  p <- p.m / N
} else {
  p.m <- apply(pool, 2, mean)
  p.m <- p.m[p.m != 0]
  p <- p.m / N
}
```

- **Explanation:**
    - Computes the mean abundance of each OTU across samples (or from the provided pool).
    - Filters out OTUs with zero abundance.
    - Normalizes these means by `N` to yield a relative abundance vector `p`.

#### 3. Calculating Occurrence Frequency

```r
spp.bi <- 1 * (spp > 0)
freq <- apply(spp.bi, 2, mean)
freq <- freq[freq != 0]

```
- **Explanation:**  
    Converts the count data into binary presence-absence data and computes the proportion of samples in which each OTU appears (its frequency).

#### 4. Merging Abundance and Frequency Data

```r
C <- merge(p, freq, by=0)
C <- C[order(C[,2]),]
C <- as.data.frame(C)
C.0 <- C[!(apply(C, 1, function(y) any(y == 0))),] 
p <- C.0[,2]
freq <- C.0[,3]
names(p) <- C.0[,1]
names(freq) <- C.0[,1]

```

- **Explanation:**
    - Merges the relative abundance (`p`) and frequency (`freq`) vectors into a data frame.
    - Orders the data frame and removes rows with zeros to ensure complete data.
    - Reassigns proper names to `p` and `freq`.

#### 5. Limit of Detection

```r
d = 1 / N

```

- **Explanation:**  
    Sets the limit of detection to the inverse of the average count per community.

#### 6. Fitting the Neutral Model via Non-linear Least Squares

```r
m.fit <- nlsLM(freq ~ pbeta(d, N * m * p, N * m * (1 - p), lower.tail = FALSE), start = list(m = 0.1))
m.ci <- confint(m.fit, 'm', level = 0.95)

```

- **Explanation:**
    - Uses `nlsLM` to fit a model where the observed frequency (`freq`) is modeled by the tail probability of a beta distribution.
    - Estimates the parameter `m` (migration or dispersal parameter) with an initial guess of 0.1.
    - Calculates the 95% confidence interval for `m`.

#### 7. Fitting the Neutral Model via Maximum Likelihood

```r
sncm.LL <- function(m, sigma){
  R = freq - pbeta(d, N * m * p, N * m * (1 - p), lower.tail = FALSE)
  R = dnorm(R, 0, sigma)
  -sum(log(R))
}
m.mle <- mle(sncm.LL, start = list(m = 0.1, sigma = 0.1), nobs = length(p))

```

- **Explanation:**
    - Defines a log-likelihood function comparing observed frequency with the beta model prediction.
    - Uses the `mle` function to estimate `m` and the error term `sigma` via maximum likelihood.

#### 8. Evaluating Model Fit (AIC, BIC, R-squared, RMSE)

```r
aic.fit <- AIC(m.mle, k = 2)
bic.fit <- BIC(m.mle)
freq.pred <- pbeta(d, N * coef(m.fit) * p, N * coef(m.fit) * (1 - p), lower.tail = FALSE)
Rsqr <- 1 - (sum((freq - freq.pred)^2)) / (sum((freq - mean(freq))^2))
RMSE <- sqrt(sum((freq - freq.pred)^2) / (length(freq) - 1))
pred.ci <- binconf(freq.pred * nrow(spp), nrow(spp), alpha = 0.05, method = "wilson", return.df = TRUE)

```

- **Explanation:**
    - Computes Akaike’s Information Criterion (AIC) and Bayesian Information Criterion (BIC) for the MLE model.
    - Predicts frequencies using the fitted model.
    - Calculates R-squared (goodness-of-fit) and RMSE.
    - Computes confidence intervals for the predicted frequencies using the Wilson method.

#### 9. Fitting Binomial and Poisson Models

The function repeats similar steps for a binomial model:

```r
bino.LL <- function(mu, sigma){ ... }
bino.mle <- mle(bino.LL, start = list(mu = 0, sigma = 0.1), nobs = length(p))
aic.bino <- AIC(bino.mle, k = 2)
bic.bino <- BIC(bino.mle)
bino.pred <- pbinom(d, N, p, lower.tail = FALSE)
Rsqr.bino <- 1 - (sum((freq - bino.pred)^2)) / (sum((freq - mean(freq))^2))
RMSE.bino <- sqrt(sum((freq - bino.pred)^2) / (length(freq) - 1))
bino.pred.ci <- binconf(bino.pred * nrow(spp), nrow(spp), alpha = 0.05, method = "wilson", return.df = TRUE)

```

And for a Poisson model:

```r
pois.LL <- function(mu, sigma){ ... }
pois.mle <- mle(pois.LL, start = list(mu = 0, sigma = 0.1), nobs = length(p))
aic.pois <- AIC(pois.mle, k = 2)
bic.pois <- BIC(pois.mle)
pois.pred <- ppois(d, N * p, lower.tail = FALSE)
Rsqr.pois <- 1 - (sum((freq - pois.pred)^2)) / (sum((freq - mean(freq))^2))
RMSE.pois <- sqrt(sum((freq - pois.pred)^2) / (length(freq) - 1))
pois.pred.ci <- binconf(pois.pred * nrow(spp), nrow(spp), alpha = 0.05, method = "wilson", return.df = TRUE)

```

- **Explanation:**
    - For each alternative model (binomial and Poisson), the function:
        - Defines a likelihood function.
        - Uses MLE to fit the model.
        - Computes AIC, BIC, predicted frequencies, R-squared, RMSE, and confidence intervals.

#### 10. Returning Results

```r
if(stats == TRUE){
  fitstats <- data.frame(... many metrics ...)
  fitstats[1,] <- c(coef(m.fit), coef(m.fit) - m.ci[1], m.mle@coef['m'], m.mle@details$value, bino.mle@details$value, pois.mle@details$value, Rsqr, Rsqr.bino, Rsqr.pois, RMSE, RMSE.bino, RMSE.pois, aic.fit, bic.fit, aic.bino, bic.bino, aic.pois, bic.pois, N, nrow(spp), length(p), d)
  return(fitstats)
} else {
  A <- cbind(p, freq, freq.pred, pred.ci[,2:3], bino.pred, bino.pred.ci[,2:3])
  A <- as.data.frame(A)
  colnames(A) <- c('p', 'freq', 'freq.pred', 'pred.lwr', 'pred.upr', 'bino.pred', 'bino.lwr', 'bino.upr')
  if(is.null(taxon)){
    B <- A[order(A[,1]),]
  } else {
    B <- merge(A, taxon, by = 0, all = TRUE)
    row.names(B) <- B[,1]
    B <- B[,-1]
    B <- B[order(B[,1]),]
  }
  return(B)
}

```

- **Explanation:**
    - If the `stats` flag is `TRUE`, the function compiles a one-row data frame (`fitstats`) with all key parameters and goodness-of-fit metrics.
    - Otherwise, it creates a detailed data frame of predictions (with confidence intervals) and merges it with taxonomic data if provided.
    - The appropriate data frame is then returned.

---

## Final Remarks

- **Expected Output from `ExtractCore`:**  
    A list containing:
    
    1. A vector of core OTU identifiers.
    2. Bray-Curtis dissimilarity ranking statistics.
    3. Ranked OTU data.
    4. An occupancy-abundance data frame annotated with core status.
    5. The OTU matrix.
    6. Sample metadata.
    7. Taxonomic information.
- **Expected Output from `sncm.fit`:**  
    Either a single-row data frame with model fit statistics (if `stats == TRUE`) or a data frame with predictions and confidence intervals for each OTU (if `stats == FALSE`).
    

Both functions are designed to give you insights into the structure of microbial communities and the extent to which core taxa are determined by neutral or deterministic processes.